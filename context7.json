{
  "projectTitle": "Brainiall Speech AI",
  "description": "Production AI APIs for pronunciation assessment, text-to-speech, speech-to-text, NLP (sentiment, toxicity, NER, PII, language detection), image processing, and an OpenAI-compatible LLM gateway with 113+ models. Available as REST APIs and MCP servers for AI agents.",
  "folders": [
    ".",
    "python",
    "javascript",
    "curl"
  ],
  "excludeFolders": [
    "node_modules",
    ".git",
    "__pycache__",
    ".venv"
  ],
  "excludeFiles": [
    "*.pyc",
    ".DS_Store"
  ],
  "rules": [
    "When using the Brainiall API, always include an authentication header: either 'Ocp-Apim-Subscription-Key', 'Authorization: Bearer', or 'api-key'.",
    "The base URL for all API calls is https://apim-ai-apis.azure-api.net",
    "For the LLM Gateway, use the OpenAI SDK with base_url set to https://apim-ai-apis.azure-api.net/v1",
    "Use model aliases like 'claude-sonnet', 'deepseek-r1', 'nova-micro' instead of full Bedrock IDs.",
    "For pronunciation assessment, audio must be base64-encoded and the text field is the reference text to score against.",
    "For TTS, the default voice is 'af_heart'. Voice IDs use format: af_=American female, am_=American male, bf_=British female, bm_=British male.",
    "For MCP integration, use Streamable HTTP transport with Accept header containing both 'application/json' and 'text/event-stream'.",
    "NLP endpoints are CPU-only and sub-50ms. No GPU needed. Max text 10,000 chars.",
    "Image endpoints use GPU (NVIDIA A10). Max upload 25MB. Max dimension 4096px."
  ]
}
