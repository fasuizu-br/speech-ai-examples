# Brainiall

> Brainiall provides production AI APIs for speech processing (pronunciation assessment, text-to-speech, speech-to-text), NLP (sentiment, toxicity, NER, PII, language detection), image processing (background removal, upscaling, face restoration), and an OpenAI-compatible LLM gateway with 113+ models from 17 providers via AWS Bedrock. All APIs are available as REST endpoints and MCP servers for AI agents.

Base URL: `https://apim-ai-apis.azure-api.net`
Authentication: `Ocp-Apim-Subscription-Key`, `Authorization: Bearer`, or `api-key` header.
Portal & API keys: `https://brainiall-portal.thankfulfield-a7857897.eastus.azurecontainerapps.io`

## Pronunciation Assessment API

- [Assess pronunciation (base64)](/v1/pronunciation/assess/base64): POST — Score spoken audio against reference text. Returns overall score (0-100), per-word and per-phoneme (ARPAbet) scores, confidence, audio quality metrics. Input: `{audio, text, format}`. 17MB ONNX model, sub-500ms latency.
- [Assess pronunciation (multipart)](/v1/pronunciation/assess): POST — Same as above, multipart/form-data upload.
- [Batch assessment](/v1/pronunciation/assess/batch): POST — Assess up to 50 audio clips in one call. Input: `{items: [{audio, text, format, id}]}`.
- [Transcribe audio](/v1/pronunciation/transcribe/base64): POST — Transcribe audio with word-level timestamps. Optionally include `text` to get embedded pronunciation scores.
- [Health check](/v1/pronunciation/health): GET — Service and model status.

## Text-to-Speech (TTS) API

- [Synthesize speech](/v1/tts/synthesize): POST — Convert text to audio. 12 voices (American + British). Input: `{text, voice, speed, format}`. Returns WAV audio. Sub-1s latency.
- [List voices](/v1/tts/voices): GET — All available voices with id, name, gender, accent.
- [Health check](/v1/tts/health): GET — Service status.

## Speech-to-Text (STT) APIs

- [Compact STT](/v1/stt/transcribe/base64): POST — Fast English transcription with word timestamps. Same 17MB model. Input: `{audio, include_timestamps}`.
- [Whisper Pro (multilingual)](/v1/whisper/transcribe/base64): POST — 99-language transcription via Whisper large-v3-turbo. Optional speaker diarization. Input: `{audio, language, diarize, format}`.
- [Health checks](/v1/stt/health): GET — Compact STT status. Also `/v1/whisper/health` for Whisper.

## NLP API

- [Toxicity detection](/v1/nlp/toxicity): POST — 6-category toxicity scoring (toxic, severe, obscene, threat, insult, identity_hate). BERT-based, sub-15ms.
- [Sentiment analysis](/v1/nlp/sentiment): POST — Positive/negative classification. Models: general, financial, twitter. Sub-10ms.
- [Named entity recognition](/v1/nlp/entities): POST — Extract persons, organizations, locations (PER/ORG/LOC/MISC) with character offsets.
- [PII detection](/v1/nlp/pii): POST — Detect emails, phones, SSNs, credit cards, IPs. Optional redaction. GDPR/CCPA compliant.
- [Language detection](/v1/nlp/language): POST — Identify 176 languages via fastText. Sub-1ms.
- [Health check](/v1/nlp/health): GET — All model statuses.

## Image Processing API

- [Remove background](/v1/image/remove-background/base64): POST — BiRefNet segmentation. Input: `{image, output_format, return_mask}`. Sub-500ms on GPU.
- [Upscale image](/v1/image/upscale/base64): POST — Real-ESRGAN 4x enhancement. Input: `{image, scale}`.
- [Restore faces](/v1/image/restore-face/base64): POST — GFPGAN face restoration. Input: `{image, upscale, enhance_background}`.
- [Health check](/v1/image/health): GET — GPU, VRAM, model status.

## LLM Gateway (OpenAI-compatible)

- [Chat completions](/v1/chat/completions): POST — OpenAI-compatible. 113+ models. Streaming SSE, tool calling, structured output, extended thinking. Works with OpenAI SDK, LiteLLM, LangChain, Cline, Cursor, Aider.
- [List models](/v1/models): GET — All available models with pricing.
- [Embeddings](/v1/embeddings): POST — Text and multimodal embeddings.
- [Health check](/v1/health): GET — Gateway and AWS connection status.

### Popular model aliases

Claude: `claude-opus`, `claude-sonnet`, `claude-haiku`. DeepSeek: `deepseek-r1`, `deepseek-v3`. Llama: `llama-3.3-70b`, `llama-4-scout`. Nova: `nova-pro`, `nova-micro`. Mistral: `mistral-large-3`. Qwen: `qwen3-32b`. Full list at `/v1/models`.

## MCP Servers (for AI agents)

- [Speech AI MCP](https://apim-ai-apis.azure-api.net/mcp/pronunciation/mcp): 10 tools — pronunciation scoring, transcription, TTS synthesis, voice listing, Whisper Pro. 8 resources, 3 prompts.
- [NLP Tools MCP](https://apim-ai-apis.azure-api.net/mcp/nlp/mcp): 6 tools — toxicity, sentiment, entities, PII, language detection. 3 resources, 3 prompts.
- [Image Tools MCP](https://apim-ai-apis.azure-api.net/mcp/image/mcp): 4 tools — background removal, upscaling, face restoration. 3 resources, 2 prompts.

MCP config for Claude Desktop / Cursor / Cline:
```json
{"mcpServers":{"brainiall-speech":{"url":"https://apim-ai-apis.azure-api.net/mcp/pronunciation/mcp","headers":{"Ocp-Apim-Subscription-Key":"YOUR_KEY"}},"brainiall-nlp":{"url":"https://apim-ai-apis.azure-api.net/mcp/nlp/mcp","headers":{"Ocp-Apim-Subscription-Key":"YOUR_KEY"}},"brainiall-image":{"url":"https://apim-ai-apis.azure-api.net/mcp/image/mcp","headers":{"Ocp-Apim-Subscription-Key":"YOUR_KEY"}}}}
```

## SDK Integration Examples

Python (LLM Gateway):
```python
from openai import OpenAI
client = OpenAI(base_url="https://apim-ai-apis.azure-api.net/v1", api_key="YOUR_KEY")
response = client.chat.completions.create(model="claude-sonnet", messages=[{"role": "user", "content": "Hello!"}])
```

Python (Pronunciation):
```python
import requests, base64
audio_b64 = base64.b64encode(open("audio.wav", "rb").read()).decode()
r = requests.post("https://apim-ai-apis.azure-api.net/v1/pronunciation/assess/base64",
    headers={"Ocp-Apim-Subscription-Key": "YOUR_KEY"},
    json={"audio": audio_b64, "text": "Hello world", "format": "wav"})
print(r.json()["overallScore"])  # 0-100
```

Node.js (LLM Gateway):
```javascript
import OpenAI from "openai";
const client = new OpenAI({ baseURL: "https://apim-ai-apis.azure-api.net/v1", apiKey: "YOUR_KEY" });
const res = await client.chat.completions.create({ model: "claude-sonnet", messages: [{ role: "user", content: "Hello!" }] });
```

## Optional

- [GitHub examples repo](https://github.com/fasuizu-br/speech-ai-examples): Python, JavaScript, curl examples and MCP configs.
- [Pricing page](https://brainiall-portal.thankfulfield-a7857897.eastus.azurecontainerapps.io/pricing): Credit packages and per-model pricing.
- [Azure Marketplace](https://azuremarketplace.microsoft.com): Search "Brainiall" for enterprise plans.
